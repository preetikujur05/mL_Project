{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9neR19FFzGJ3",
        "outputId": "ccb504df-3c4c-470e-e85e-8285f2b7c47e"
      },
      "outputs": [],
      "source": [
        "# Notebook 4 — VGG16 Transfer Learning (7-class)\n",
        "# Colab-ready. Run top-to-bottom.\n",
        "\n",
        "# 0) Imports & environment checks\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCeiLj8E1nbu",
        "outputId": "538f8130-97f4-48b3-8906-c1d4906b5a54"
      },
      "outputs": [],
      "source": [
        "# 1) GPU safety (prevent TF from grabbing all memory)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Enabled memory growth on GPU(s).\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not set memory growth:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xne8jLwu1qUB"
      },
      "outputs": [],
      "source": [
        "# 2) Config (update paths if needed)\n",
        "\n",
        "IMAGE_FOLDER = \"/content/drive/MyDrive/HAM10000_images\"   # where images live (Notebook1 should have created/cleaned this)\n",
        "SPLITS_DIR = \"/content/drive/MyDrive/splits\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/models\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "RANDOM_STATE = 42\n",
        "NUM_CLASSES = 7\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WPYo20p1tlg",
        "outputId": "6ed7e751-6228-4b88-9f43-acd6c326e51f"
      },
      "outputs": [],
      "source": [
        "# 3) Load CSV splits\n",
        "df_train = pd.read_csv(os.path.join(SPLITS_DIR, \"df_train.csv\"))\n",
        "df_val   = pd.read_csv(os.path.join(SPLITS_DIR, \"df_val.csv\"))\n",
        "df_test  = pd.read_csv(os.path.join(SPLITS_DIR, \"df_test.csv\"))\n",
        "print(\"Train rows:\", len(df_train), \"Val rows:\", len(df_val), \"Test rows:\", len(df_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc2iMll51yeN"
      },
      "outputs": [],
      "source": [
        "# 4) Ensure filepath column exists (create if missing)\n",
        "for d in [df_train, df_val, df_test]:\n",
        "    if 'filepath' not in d.columns:\n",
        "        d['filename'] = d['image_id'].astype(str) + '.jpg'\n",
        "        d['filepath'] = d['filename'].apply(lambda x: os.path.join(IMAGE_FOLDER, x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuFoSnHT13wQ",
        "outputId": "7aca3bf5-70ca-4861-e230-3a878751229e"
      },
      "outputs": [],
      "source": [
        "# 5) Sanity check classes\n",
        "if 'dx' not in df_train.columns:\n",
        "    raise ValueError(\"Expected column 'dx' in CSVs with class labels (7 classes).\")\n",
        "print(\"Train label counts:\\n\", df_train['dx'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3s8q6mR16V0",
        "outputId": "c431fe96-9642-4e46-daf9-868fda9d11c2"
      },
      "outputs": [],
      "source": [
        "# 6) Generators — use VGG preprocessing (ImageNet mean subtraction / scaling)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=vgg_preprocess,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    zoom_range=0.10,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=vgg_preprocess)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=vgg_preprocess)\n",
        "\n",
        "train_flow = train_datagen.flow_from_dataframe(\n",
        "    df_train, x_col='filepath', y_col='dx',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "val_flow = val_datagen.flow_from_dataframe(\n",
        "    df_val, x_col='filepath', y_col='dx',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "test_flow = test_datagen.flow_from_dataframe(\n",
        "    df_test, x_col='filepath', y_col='dx',\n",
        "    target_size=(IMG_SIZE, IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_flow.class_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "SIouTAN419HY",
        "outputId": "28a4469b-e9df-4e24-ea85-0b8779609801"
      },
      "outputs": [],
      "source": [
        "# 7) Build model: VGG16 (include_top=False) + GAP + Dense(256) + Dropout + Dense(num_classes)\n",
        "base_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "# Freeze most layers. We will unfreeze last few if we fine-tune later.\n",
        "for layer in base_vgg.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_vgg.output\n",
        "x = GlobalAveragePooling2D(name='gap')(x)   # -> (512,)\n",
        "x = Dense(256, activation='relu', name='dense_256')(x)\n",
        "x = Dropout(0.5, name='dropout')(x)\n",
        "preds = Dense(NUM_CLASSES, activation='softmax', name='preds')(x)\n",
        "\n",
        "vgg_model = Model(inputs=base_vgg.input, outputs=preds)\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vgg_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVatWuo-2AEP"
      },
      "outputs": [],
      "source": [
        "# 8) Callbacks & checkpointing\n",
        "checkpoint_path = os.path.join(OUTPUT_DIR, \"vgg16_best.h5\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDjJYRMB2HTx",
        "outputId": "00d7d10e-ff29-429e-b090-b87ae9eba549"
      },
      "outputs": [],
      "source": [
        "# 9) Train (head-only first)\n",
        "history = vgg_model.fit(\n",
        "    train_flow,\n",
        "    validation_data=val_flow,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXcYALVo2JJy",
        "outputId": "3b93d845-01a5-4820-a502-fd07128b30d1"
      },
      "outputs": [],
      "source": [
        "# 10) Save last weights & model\n",
        "vgg_model.save(os.path.join(OUTPUT_DIR, \"vgg16_last.h5\"))\n",
        "print(\"Saved VGG16 models to\", OUTPUT_DIR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "Fa6ajxVn2MIF",
        "outputId": "a4fee4f8-a60e-4402-8ec0-442572a87838"
      },
      "outputs": [],
      "source": [
        "# 11) Plot training curves\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend(); plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend(); plt.title('Loss')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YSlGReeX2OJs",
        "outputId": "676a5799-b620-4a3a-d2c9-9dc402907f46"
      },
      "outputs": [],
      "source": [
        "# 12) Evaluate best model on test set\n",
        "best = load_model(checkpoint_path)\n",
        "test_steps = int(np.ceil(test_flow.n / test_flow.batch_size))\n",
        "loss, acc = best.evaluate(test_flow, steps=test_steps, verbose=1)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%, test loss: {loss:.4f}\")\n",
        "\n",
        "# 13) Predictions -> confusion matrix and classification report\n",
        "test_flow.reset()\n",
        "y_prob = best.predict(test_flow, steps=test_steps, verbose=1)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "y_true = test_flow.classes  # integer indices\n",
        "\n",
        "inv_class_map = {v:k for k,v in train_flow.class_indices.items()}\n",
        "y_pred_labels = [inv_class_map[int(i)] for i in y_pred]\n",
        "y_true_labels = [inv_class_map[int(i)] for i in y_true]\n",
        "\n",
        "print(\"\\nClassification Report (VGG16 Transfer):\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=list(inv_class_map.values()))\n",
        "plt.figure(figsize=(9,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=list(inv_class_map.values()), yticklabels=list(inv_class_map.values()))\n",
        "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix (VGG16 Transfer)')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sxr0BBm52RLW"
      },
      "outputs": [],
      "source": [
        "# 14) Optional: Fine-tune last K layers (unfreeze and retrain with lower LR)\n",
        "# If you want to fine-tune, uncomment and run the following block AFTER the head-only training above\n",
        "\"\"\"\n",
        "# Unfreeze last N layers (e.g., last 8 conv layers)\n",
        "N = 8\n",
        "for layer in base_vgg.layers[-N:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile with lower LR\n",
        "vgg_model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vgg_finetune_history = vgg_model.fit(\n",
        "    train_flow,\n",
        "    validation_data=val_flow,\n",
        "    epochs=10,\n",
        "    callbacks=get_callbacks(os.path.join(OUTPUT_DIR, \"vgg16_finetune_best.h5\"))\n",
        ")\n",
        "# Save finetuned model\n",
        "vgg_model.save(os.path.join(OUTPUT_DIR, \"vgg16_finetuned.h5\"))\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "ZrJTP07a2TTy",
        "outputId": "4372aaa0-3a83-4eac-ae16-17e2cf1652ae"
      },
      "outputs": [],
      "source": [
        "# 15) Inference helper (upload images in Colab and run)\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_single_vgg(model, img_path, target_size=(IMG_SIZE,IMG_SIZE)):\n",
        "    img = load_img(img_path, target_size=target_size)\n",
        "    arr = img_to_array(img)  # in 0..255\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    arr = vgg_preprocess(arr)  # apply same preprocessing as training\n",
        "    prob = model.predict(arr)[0]\n",
        "    idx = np.argmax(prob)\n",
        "    label = inv_class_map[idx]\n",
        "    return label, prob[idx], prob\n",
        "\n",
        "print(\"To run inference: upload a file using files.upload()\")\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    label, conf, allprob = predict_single_vgg(best, fn)\n",
        "    print(f\"File: {fn}  -> Predicted: {label} ({conf*100:.2f}%)\")\n",
        "    print(\"All class probs:\", {inv_class_map[i]: float(allprob[i]) for i in range(len(allprob))})\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
