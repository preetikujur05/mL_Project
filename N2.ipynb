{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tUzMPSTqZnI",
        "outputId": "5d89048a-aa2a-42c6-ed38-34a321e770bb"
      },
      "outputs": [],
      "source": [
        "# Notebook 2 — Binary CNN\n",
        "# Colab-ready. Run top-to-bottom.\n",
        "\n",
        "# 0) Install / imports (no TF reinstall — use environment's TF)\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enuRg_qVwGFc"
      },
      "outputs": [],
      "source": [
        "# 1) GPU safety (prevent TF from grabbing all GPU memory)\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"Enabled memory growth on GPU(s).\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not set memory growth:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnrUia0hwIq3"
      },
      "outputs": [],
      "source": [
        "# 2) Config — update paths if needed\n",
        "IMAGE_FOLDER = \"/content/drive/MyDrive/HAM10000_images\"   # images folder created by Notebook 1\n",
        "SPLITS_DIR = \"/content/drive/MyDrive/splits\"              # output from Notebook 1\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/models\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "RANDOM_STATE = 42\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I1t6GemzTaE",
        "outputId": "2fa6667a-a2a8-4546-df4b-b9b54f127dd4"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBY_wzH-y1Q7",
        "outputId": "b7b64c2b-4854-4e11-9ad4-da7ae51e3f80"
      },
      "outputs": [],
      "source": [
        "!find /content/drive -type f -name \"df_train.csv\"\n",
        "!find /content/drive -type f -name \"df_val.csv\"\n",
        "!find /content/drive -type f -name \"df_test.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4IZO81BwLP1",
        "outputId": "04db1a4f-e58a-44a6-a099-6803a1483863"
      },
      "outputs": [],
      "source": [
        "# 3) Load CSV splits (Notebook 1 must have created these)\n",
        "df_train = pd.read_csv(os.path.join(SPLITS_DIR, \"df_train.csv\"))\n",
        "df_val   = pd.read_csv(os.path.join(SPLITS_DIR, \"df_val.csv\"))\n",
        "df_test  = pd.read_csv(os.path.join(SPLITS_DIR, \"df_test.csv\"))\n",
        "\n",
        "# If Notebook1 saved oversampled train as df_train.csv then use it directly; else adapt accordingly.\n",
        "print(\"Train rows:\", len(df_train), \"Val rows:\", len(df_val), \"Test rows:\", len(df_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDfINpxfwN4v"
      },
      "outputs": [],
      "source": [
        "# 4) Ensure we have file paths in CSVs (if not present, create)\n",
        "for d in [df_train, df_val, df_test]:\n",
        "    if 'filepath' not in d.columns:\n",
        "        d['filename'] = d['image_id'].astype(str) + '.jpg'\n",
        "        d['filepath'] = d['filename'].apply(lambda x: os.path.join(IMAGE_FOLDER, x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxuBh43ewQQD",
        "outputId": "94ffff50-1a83-4db1-b16d-0bbd292548e9"
      },
      "outputs": [],
      "source": [
        "# 5) Build binary label column if not present (benign vs malignant mapping used in your code)\n",
        "benign_classes = ['bkl', 'df', 'nv', 'vasc']\n",
        "for df in [df_train, df_val, df_test]:\n",
        "    if 'binary_label' not in df.columns:\n",
        "        df['binary_label'] = df['dx'].apply(lambda x: 'benign' if x in benign_classes else 'malignant')\n",
        "\n",
        "print(\"Example binary label counts (train):\\n\", df_train['binary_label'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nT4QDHlwSs-",
        "outputId": "90d0b291-4526-45a6-c4e9-95a45ee6e057"
      },
      "outputs": [],
      "source": [
        "# 6) Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.10,\n",
        "    height_shift_range=0.10,\n",
        "    zoom_range=0.10,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_flow = train_datagen.flow_from_dataframe(\n",
        "    df_train, x_col='filepath', y_col='binary_label',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "\n",
        "val_flow = val_datagen.flow_from_dataframe(\n",
        "    df_val, x_col='filepath', y_col='binary_label',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "test_flow = test_datagen.flow_from_dataframe(\n",
        "    df_test, x_col='filepath', y_col='binary_label',\n",
        "    target_size=(IMG_SIZE,IMG_SIZE), color_mode='rgb',\n",
        "    class_mode='categorical', batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "vExci8u1wVQ6",
        "outputId": "dbe4e5a0-8a4e-4502-b164-6929d4d007d1"
      },
      "outputs": [],
      "source": [
        "# 7) Build Binary CNN model (matches your architecture but with Input & BatchNorm)\n",
        "def build_binary_cnn(input_shape=(IMG_SIZE,IMG_SIZE,3)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv2D(32, (3,3), activation='relu', padding='valid'),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv2D(128, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "binary_model = build_binary_cnn()\n",
        "binary_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRei1a2xwXS2",
        "outputId": "9232810c-f142-4ab8-a912-6c75b53b9202"
      },
      "outputs": [],
      "source": [
        "# 8) Callbacks and checkpoint\n",
        "checkpoint_path = os.path.join(OUTPUT_DIR, \"binary_cnn_best.h5\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1),\n",
        "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# 9) Train\n",
        "history = binary_model.fit(\n",
        "    train_flow,\n",
        "    validation_data=val_flow,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "bGZsCxTrwaYt",
        "outputId": "b42dd72e-6f9d-47f3-9a08-2daf1692657e"
      },
      "outputs": [],
      "source": [
        "# 10) Save final model (already saved best via checkpoint)\n",
        "binary_model.save(os.path.join(OUTPUT_DIR, \"binary_cnn_last.h5\"))\n",
        "print(\"Saved models to\", OUTPUT_DIR)\n",
        "\n",
        "# 11) Plot training curves\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend(); plt.title('Accuracy')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend(); plt.title('Loss')\n",
        "plt.show()\n",
        "\n",
        "# 12) Evaluate on test set\n",
        "# Load best model (safe)\n",
        "best = load_model(checkpoint_path)\n",
        "test_steps = int(np.ceil(test_flow.n / test_flow.batch_size))\n",
        "loss, acc = best.evaluate(test_flow, steps=test_steps, verbose=1)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%, test loss: {loss:.4f}\")\n",
        "\n",
        "# 13) Predictions -> confusion matrix and classification report\n",
        "test_flow.reset()\n",
        "y_prob = best.predict(test_flow, steps=test_steps, verbose=1)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "y_true = test_flow.classes  # keras flow_from_dataframe stores integer indices in .classes\n",
        "\n",
        "# Map numeric indices to class labels\n",
        "label_map = (train_flow.class_indices)  # e.g. {'benign':0,'malignant':1}\n",
        "inv_label_map = {v:k for k,v in label_map.items()}\n",
        "y_pred_labels = [inv_label_map[int(i)] for i in y_pred]\n",
        "y_true_labels = [inv_label_map[int(i)] for i in y_true]\n",
        "\n",
        "print(\"\\nClassification Report (binary):\")\n",
        "print(classification_report(y_true_labels, y_pred_labels))\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=list(inv_label_map.values()))\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=list(inv_label_map.values()), yticklabels=list(inv_label_map.values()))\n",
        "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9WZ2FcK1edS",
        "outputId": "90732afd-5414-4721-a62d-213224022e8b"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/MyDrive/models\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE2DXT0o1lX_",
        "outputId": "64b2afeb-74bf-4385-81fb-5c82f98c90c7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/models/binary_cnn_best.h5\"\n",
        "best = load_model(checkpoint_path)\n",
        "print(\"Model loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptolgJ593E4n",
        "outputId": "3b31629c-e02f-4d5d-dcb6-9a657b8f9cf4"
      },
      "outputs": [],
      "source": [
        "test_steps = int(np.ceil(test_flow.n / test_flow.batch_size))\n",
        "loss, acc = best.evaluate(test_flow, steps=test_steps)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%, Test loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_J7a_zc3I3F",
        "outputId": "d7ced0e5-8704-42ee-f532-5d5ac9d09156"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "test_flow.reset()\n",
        "y_prob = best.predict(test_flow, steps=test_steps)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "y_true = test_flow.classes\n",
        "\n",
        "label_map = test_flow.class_indices\n",
        "inv_label_map = {v:k for k,v in label_map.items()}\n",
        "\n",
        "y_pred_labels = [inv_label_map[i] for i in y_pred]\n",
        "y_true_labels = [inv_label_map[i] for i in y_true]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_labels, y_pred_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "UuKy0fE53Ldm",
        "outputId": "c1410bc8-43c7-42b5-9656-5e8ca2c47ef3"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=list(inv_label_map.values()),\n",
        "            yticklabels=list(inv_label_map.values()))\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "0hE0drmdweDl",
        "outputId": "88e408bf-7ceb-49a6-b1be-3016d0c4faff"
      },
      "outputs": [],
      "source": [
        "# 14) Inference: upload an image in Colab and predict\n",
        "# Run the cell below and select an image file to upload. It will print predicted label and confidence.\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def predict_single_image(model, img_path, target_size=(IMG_SIZE,IMG_SIZE)):\n",
        "    img = load_img(img_path, target_size=target_size)\n",
        "    arr = img_to_array(img) / 255.0\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    prob = model.predict(arr)[0]\n",
        "    idx = np.argmax(prob)\n",
        "    label = inv_label_map[idx]\n",
        "    return label, prob[idx], prob\n",
        "\n",
        "print(\"To run inference: upload a file using files.upload()\")\n",
        "uploaded = files.upload()  # interactive: pick file(s)\n",
        "for fn in uploaded.keys():\n",
        "    label, conf, allprob = predict_single_image(best, fn)\n",
        "    print(f\"File: {fn}  -> Predicted: {label} ({conf*100:.2f}%)  probs: {allprob}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
